{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cdccc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de9561f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e494017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\ENG-Mahmoud/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2024-10-11 Python-3.9.13 torch-1.13.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\ENG-Mahmoud/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2024-10-11 Python-3.9.13 torch-1.13.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 212 layers, 20869098 parameters, 0 gradients, 47.9 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video with violations saved at Detection Output\\Detection_2024-10-11-11-13-PM.mp4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Define global parameters\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "NMS_THRESHOLD = 0.4\n",
    "VIDEO_FILE = \"video2.mp4\"\n",
    "OUTPUT_DIR = \"Detection Output\"\n",
    "FRAME_SIZE = (1020, 600)\n",
    "CLASSES = [\"Helmet\", \"No Safety Vest\", \"No Helmet\", \"Safety Vest\", \"Shoes\"]\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def load_model(weights_path='yolov5s.pt', conf=0.5, iou=0.4):\n",
    "    \"\"\"Load YOLOv5 model with error handling and custom configuration.\"\"\"\n",
    "    try:\n",
    "        model = torch.hub.load('ultralytics/yolov5', 'custom', path=weights_path, force_reload=True)\n",
    "        model.conf = conf  # Confidence threshold\n",
    "        model.iou = iou  # NMS IoU threshold\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the model: {e}\")\n",
    "        exit()\n",
    "\n",
    "def process_frame(frame, model):\n",
    "    \"\"\"Run YOLOv5 inference on a single frame and return predictions.\"\"\"\n",
    "    frame_resized = cv2.resize(frame, FRAME_SIZE)\n",
    "    results = model(frame_resized)\n",
    "    pred = results.pred[0].cpu().numpy()  # Extract predictions\n",
    "    return pred, frame_resized\n",
    "\n",
    "def draw_boxes(frame, predictions, label, color):\n",
    "    \"\"\"Draw bounding boxes and labels on a frame.\"\"\"\n",
    "    for obj in predictions:\n",
    "        x1, y1, x2, y2 = map(int, obj[:4])\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(frame, label, (x1, y1 - 10), FONT, 0.5, color, 2, cv2.LINE_AA)\n",
    "\n",
    "def check_safety_gear(workers, helmets, vests, frame):\n",
    "    \"\"\"Check workers for missing helmets or vests and return the frames with violations.\"\"\"\n",
    "    no_safety_frames = []\n",
    "    violation_detected = False\n",
    "    \n",
    "    for worker in workers:\n",
    "        x1, y1, x2, y2 = map(int, worker[:4])\n",
    "        # Check if the worker has a helmet or vest\n",
    "        has_helmet = any(x1 <= h[2] and x2 >= h[0] and y1 <= h[3] and y2 >= h[1] for h in helmets)\n",
    "        has_vest = any(x1 <= v[2] and x2 >= v[0] and y1 <= v[3] and y2 >= v[1] for v in vests)\n",
    "\n",
    "        # Determine what safety gear is missing\n",
    "        if not has_helmet and not has_vest:\n",
    "            # No Helmet and No Vest: Yellow\n",
    "            draw_boxes(frame, [worker], \"No Helmet and Vest\", (0, 255, 255))  # Yellow box\n",
    "            violation_detected = True\n",
    "        elif not has_helmet:\n",
    "            # No Helmet: Blue\n",
    "            draw_boxes(frame, [worker], \"No Helmet\", (255, 0, 0))  # Blue box\n",
    "            violation_detected = True\n",
    "        elif not has_vest:\n",
    "            # No Vest: Red\n",
    "            draw_boxes(frame, [worker], \"No Vest\", (0, 0, 255))  # Red box\n",
    "            violation_detected = True\n",
    "\n",
    "        if violation_detected:\n",
    "            no_safety_frames.append(frame.copy())  # Save the frame with the violation\n",
    "\n",
    "    return no_safety_frames, violation_detected\n",
    "\n",
    "def get_output_filename():\n",
    "    \"\"\"Generate output filename with current date and time.\"\"\"\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d-%I-%M-%p\")  # Format: YYYY-MM-DD-HH-MM-am/pm\n",
    "    filename = f\"Detection_{current_time}.mp4\"\n",
    "    return os.path.join(OUTPUT_DIR, filename)\n",
    "\n",
    "def main():\n",
    "    # Load two models: one for person detection (COCO), and one for safety gear detection\n",
    "    coco_model = load_model('yolov5s.pt', conf=CONFIDENCE_THRESHOLD, iou=NMS_THRESHOLD)  # COCO model\n",
    "    safety_model = load_model('best.pt', conf=CONFIDENCE_THRESHOLD, iou=NMS_THRESHOLD)  # Custom model for safety detection\n",
    "\n",
    "    # Open video file for reading\n",
    "    cap = cv2.VideoCapture(VIDEO_FILE)\n",
    "\n",
    "    # Initialize video writer as None, only create it if we detect something\n",
    "    out = None\n",
    "    violations_detected = False  # Track if any violations are found\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Step 1: Detect people using the COCO-trained YOLOv5 model\n",
    "        predictions, frame_resized = process_frame(frame, coco_model)\n",
    "        persons = predictions[predictions[:, 5] == 0]  # Class '0' in COCO is 'person'\n",
    "\n",
    "        if len(persons) > 0:\n",
    "            # Step 2: If a person is detected, run safety gear detection\n",
    "            safety_predictions, _ = process_frame(frame, safety_model)\n",
    "\n",
    "            # Extract detections by class\n",
    "            helmets = safety_predictions[safety_predictions[:, 5] == CLASSES.index('Helmet')]\n",
    "            no_helmets = safety_predictions[safety_predictions[:, 5] == CLASSES.index('No Helmet')]\n",
    "            vests = safety_predictions[safety_predictions[:, 5] == CLASSES.index('Safety Vest')]\n",
    "            no_vests = safety_predictions[safety_predictions[:, 5] == CLASSES.index('No Safety Vest')]\n",
    "\n",
    "            # Check and mark workers without safety gear, returning frames with violations\n",
    "            no_safety_frames, violation_detected = check_safety_gear(persons, helmets, vests, frame_resized)\n",
    "\n",
    "            if violation_detected:\n",
    "                # Initialize video writer only when violations are detected\n",
    "                if out is None:\n",
    "                    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "                    output_file = get_output_filename()\n",
    "                    out = cv2.VideoWriter(output_file, fourcc, cap.get(cv2.CAP_PROP_FPS), FRAME_SIZE)\n",
    "                \n",
    "                # Write the frames with violations to the output video\n",
    "                for no_safety_frame in no_safety_frames:\n",
    "                    out.write(no_safety_frame)\n",
    "\n",
    "                violations_detected = True\n",
    "\n",
    "        # Optionally show the processed frame in a window\n",
    "        cv2.imshow('Processed Frame', frame_resized)\n",
    "\n",
    "        # Quit if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # If a video writer was created and no violations were detected, delete the output file\n",
    "    if out is not None:\n",
    "        out.release()\n",
    "        if not violations_detected:\n",
    "            os.remove(output_file)\n",
    "            print(\"No violations detected, video file deleted.\")\n",
    "        else:\n",
    "            print(f\"Video with violations saved at {output_file}\")\n",
    "    else:\n",
    "        print(\"No violations detected, no video created.\")\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1297115a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d354e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784cfdf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
